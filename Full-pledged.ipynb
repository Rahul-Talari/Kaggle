{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Time Series Data and Time Series Analysis?\n",
    "\n",
    "1. **Definition**\n",
    "2. **Real-Time Examples**\n",
    "3. **Key Characteristics of Time Series Data**\n",
    "4. **Goals of Time Series Analysis**\n",
    "5. **Components**\n",
    "   - Trend\n",
    "   - Seasonality\n",
    "   - Cyclic\n",
    "   - Residuals\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stationarity\n",
    "\n",
    "1. **Why do we need stationarity**\n",
    "2. **Types of Stationarity**  \n",
    "   - Weak stationarity  \n",
    "   - Strong stationarity  \n",
    "3. **Testing for Weak Stationarity**\n",
    "4. **Testing for Strict Stationarity**  \n",
    "5. **Making Time Series Stationary**\n",
    "   1. **Differencing**  \n",
    "      - First order  \n",
    "      - Second order  \n",
    "   2. **Transformation**  \n",
    "      - Logarithmic  \n",
    "      - Power  \n",
    "      - Box-Cox  \n",
    "   3. **Detrending**  \n",
    "      - Linear  \n",
    "      - Moving Average  \n",
    "\n",
    "6. **Seasonal Adjustment**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stationarity:\n",
    "- In time series analysis, stationarity refers to a stochastic process whose statistical properties, including {mean, variance, autocorrelation} remain constant over time.\n",
    "- A stochastic process is a mathematical concept describing a system that evolves over time in a random or unpredictable manner.\n",
    "- Stationary series has no trends or seasonality, making it more predictable for analysis and modeling\n",
    "   ![Stationarity](https://cdn-images-1.medium.com/max/1600/1*tkx0_wwQ2JT7pSlTeg4yzg.png)\n",
    "\n",
    "\n",
    "1. Most statistical smoothing techniques and time series analysis techniques assume that the data is stationary.\n",
    "\n",
    "2.  \n",
    "   ### Strict Stationarity\n",
    "   - The **joint probability distribution** of observations remains unchanged when shifted in time.\n",
    "   - All statistical properties (**mean, variance, higher-order moments, skewness, kurtosis**) are constant over time.\n",
    "   - It is a stricter condition, rarely observed in real-world data.\n",
    "\n",
    "   ### Weak Stationarity (Wide-Sense Stationarity)\n",
    "   - **Constant Mean:** The mean does not vary with time.\n",
    "   - **Constant Variance:** The variance is fixed and does not change over time.\n",
    "   - **Time-Invariant Autocovariance:** Autocovariance depends only on the lag, not the specific time points.\n",
    "\n",
    "   **Note:** Weak stationarity is more practical and commonly used in time series analysis.\n",
    "\n",
    "3. **Weak Stationarity Tests:**\n",
    "   - Augmented Dickey-Fuller (ADF) Test\n",
    "   - KPSS Test\n",
    "   - Phillips-Perron (PP) Test\n",
    "   - ACF & PACF Plots\n",
    "   - Ljung-Box Test\n",
    "   - Variance Ratio Test\n",
    "\n",
    "4. **Strict (Strong) Stationarity Tests:**\n",
    "   - Detrended Fluctuation Analysis (DFA)\n",
    "   - Jarque-Bera Test\n",
    "   - Kolmogorov-Smirnov (KS) Test\n",
    "   - Cusum Test\n",
    "\n",
    "5. **Making Time Series Stationary**\n",
    "\n",
    "   a. **Differencing** makes a time series stationary by subtracting previous values from current ones.\n",
    "      - **1st Order Differencing:** Subtracts value at time `t-1` from value at time `t` to remove linear trends.\n",
    "      - **2nd Order Differencing:** Applies differencing again to remove quadratic trends or further non-stationarity.\n",
    "\n",
    "         **Cons:**\n",
    "         - Can lose long-term trends or relationships.\n",
    "         - May not work well for high volatility or structural changes.\n",
    "\n",
    "   b. **Transformations:**\n",
    "      - **Logarithmic:** Applies the natural logarithm to the data to stabilize variance.\n",
    "      - **Power:** Raises the data to a power (e.g., square root or cube) to stabilize variance.\n",
    "      - **Box-Cox:**\n",
    "         * The Box-Cox transformation is a family of power transformations used to stabilize variance.\n",
    "         * It makes data more normally distributed by applying a parameterized function to positive continuous data.\n",
    "           - y(λ) = (Y^λ - 1) / λ, for λ ≠ 0\n",
    "           - Y(0) = ln(Y), for λ = 0\n",
    "\n",
    "   c. **Detrending**: It is used to remove trends from time series data. \n",
    "      - **Linear Detrending:** This method involves fitting a linear regression line to the data and subtracting the fitted values from the original data. This helps remove any linear trends.\n",
    "      - **Moving Average Detrending:** This method involves calculating the moving average of the data over a specified window size. The moving average is then subtracted from the original data to remove any trends.\n",
    "\n",
    "\n",
    "6. **Seasonal Adjustment**:  \n",
    "   - Removing the seasonal component from time series data helps isolate the underlying trend and irregular components.  \n",
    "   - STL Decomposition can be used.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "# Download data for a specific stock (e.g., Apple Inc.)\n",
    "df = yf.download('AAPL', start='2020-01-01', end='2025-01-01')\n",
    "\n",
    "# Display the data\n",
    "print(df.head(),\"\\n\\n\\n\",df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Decomposition\n",
    "\n",
    "1. **Types of Decomposition Methods**\n",
    "   - Additive\n",
    "   - Multiplicative\n",
    "2. **STL Decomposition**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Decomposition\n",
    "### There are 2 types of Decomposition:\n",
    "\n",
    "#### Additive Seasonal Decomposition\n",
    "- Assumes constant seasonal variation regardless of trend.\n",
    "- Can work with negative or zero values.\n",
    "\n",
    "1. Trend Calculation (T):\n",
    "    * $T_t = \\text{Moving Average of the time series at time } t$\n",
    "    * Smooth the data using a moving average to capture the long-term trend.\n",
    "2. De-trended Data (D):\n",
    "    *  $D_t = Y_t - T_t$\n",
    "    * Subtract the trend (T) from the original data (Y) to get the de-trended data.\n",
    "3. Seasonal Component (S): \n",
    "    * $S_t = \\frac{1}{N} \\sum_{i=1}^{N} D_t$ for the same period (e.g., month)\n",
    "    * Calculate the average of de-trended values for each period (e.g., monthly average for all January values).\n",
    "4. Residual Component (R):\n",
    "    * $R_t = Y_t - T_t - S_t$\n",
    "    * Subtract both the trend (T) and seasonal (S) components from the original data (Y).\n",
    "\n",
    "#### Multiplicative Seasonal Decomposition \n",
    "- The multiplicative model can't handle zero or negative values because it involves multiplying the components (seasonal, trend, residual).\n",
    "- Multiplying by zero or a negative number would distort the results, making the decomposition invalid.\n",
    "- Best when seasonal variation increases with the trend.\n",
    "\n",
    "1. Trend Calculation (T): \n",
    "    * $T_t = \\text{Moving Average of the time series at time } t$\n",
    "    * Smooth the data using a moving average to capture the long-term trend.\n",
    "2. De-trended Data (D): \n",
    "    * $D_t = \\frac{Y_t}{T_t}$\n",
    "    * Divide the original data (Y) by the trend (T) to get the de-trended data.\n",
    "3. Seasonal Component (S): \n",
    "    * $S_t = \\frac{1}{N} \\sum_{i=1}^{N} D_t$ for the same period (e.g., month)\n",
    "    * Calculate the average of the de-trended data for each period, just like in additive decomposition.\n",
    "4. Residual Component (R): \n",
    "    * $R_t = \\frac{Y_t}{T_t \\cdot S_t}$\n",
    "    * Divide the original data (Y) by both the trend (T) and seasonal (S) components to get the residuals.\n",
    "    \n",
    "\n",
    "<small>\n",
    "\n",
    "##### Exceptional Cases:\n",
    "\n",
    "- **Outliers**: Both models are sensitive to extreme outliers.\n",
    "- **Non-stationary Data**: Models may struggle with data having a changing trend.\n",
    "- **Short Time Series**: Both methods may not perform well with very few data points.\n",
    "\n",
    "</small>\n",
    "\n",
    "![Additive decomposition & Multiplicative decomposition](https://cf3.ppt-online.org/files3/slide/k/KB2ir9by6pTG3LU78tZquAENfman0HPCdQOIwF/slide-4.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "\n",
    "# Additive Decomposition\n",
    "additive_decomposition = seasonal_decompose(df['Volume'], model='additive', period=12)\n",
    "\n",
    "# Plot Additive Decomposition\n",
    "fig, axes = plt.subplots(4, 1, figsize=(10, 8))\n",
    "additive_decomposition.observed.plot(ax=axes[0], title='Observed Data')\n",
    "additive_decomposition.trend.plot(ax=axes[1], title='Trend Component')\n",
    "additive_decomposition.seasonal.plot(ax=axes[2], title='Seasonal Component')\n",
    "additive_decomposition.resid.plot(ax=axes[3], title='Residual Component')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Multiplicative Decomposition\n",
    "multiplicative_decomposition = seasonal_decompose(df['Volume'], model='multiplicative', period=12)\n",
    "\n",
    "# Plot Multiplicative Decomposition\n",
    "fig, axes = plt.subplots(4, 1, figsize=(10, 8))\n",
    "multiplicative_decomposition.observed.plot(ax=axes[0], title='Observed Data')\n",
    "multiplicative_decomposition.trend.plot(ax=axes[1], title='Trend Component')\n",
    "multiplicative_decomposition.seasonal.plot(ax=axes[2], title='Seasonal Component')\n",
    "multiplicative_decomposition.resid.plot(ax=axes[3], title='Residual Component')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small>\n",
    "\n",
    "## STL Decomposition Overview\n",
    "\n",
    "- STL breaks a time series into **Trend**, **Seasonal**, and **Residual** components using the LOESS (Locally Estimated Scatterplot Smoothing) method.\n",
    "- It is robust, flexible, and highly suitable for data with changing seasonality or outliers.\n",
    "- STL decomposition is designed for additive data:\n",
    "\n",
    "  \\[\n",
    "  Y_t = T_t + S_t + R_t\n",
    "  \\]\n",
    "\n",
    "- For multiplicative data, apply a logarithmic transformation to convert it into an additive form:\n",
    "\n",
    "  \\[\n",
    "  log(Y_t) = log(T_t) + log(S_t) + log(R_t)\n",
    "  \\]\n",
    "\n",
    "  After STL decomposition, exponentiate the results to revert to the original scale.\n",
    "\n",
    "---\n",
    "\n",
    "## STL Decomposition Process\n",
    "\n",
    "#### 1. **Seasonal Component (S)**:\n",
    "- STL uses LOESS to estimate the seasonal component.\n",
    "- The seasonal pattern is smoothed over a cycle (e.g., months, quarters).\n",
    "- LOESS smoothing allows for changing seasonality over time, unlike in additive decomposition, where seasonality is constant.\n",
    "\n",
    "  \\[\n",
    "  S_t = LOESS smoothing of the time series based on seasonality\n",
    "  \\]\n",
    "\n",
    "#### 2. **De-trended Data (D)**:\n",
    "- After removing the seasonal component, the data becomes de-seasonalized.\n",
    "- The de-seasonalized data contains only the trend and residuals without any seasonal influence.\n",
    "\n",
    "  \\[\n",
    "  D_t = Y_t - S_t\n",
    "  \\]\n",
    "\n",
    "#### 3. **Trend Component (T)**:\n",
    "- LOESS is applied again to the de-seasonalized data to estimate the Trend component.\n",
    "- LOESS smoothing allows more flexibility, capturing local variations in the trend, which is more adaptive compared to simple moving averages in additive decomposition.\n",
    "\n",
    "  \\[\n",
    "  T_t = LOESS smoothing of (D_t)\n",
    "  \\]\n",
    "\n",
    "#### 4. **Residual Component (R)**:\n",
    "- The residuals represent the noise or errors after extracting the trend and seasonal components.\n",
    "- The residuals are calculated by subtracting both the trend and seasonal components from the original data.\n",
    "\n",
    "  \\[\n",
    "  R_t = Y_t - T_t - S_t\n",
    "  \\]\n",
    "\n",
    "---\n",
    "\n",
    "## Iterative Refinement\n",
    "- STL performs this decomposition process iteratively.\n",
    "- The iterative process refines the seasonal and trend components, making STL more robust to outliers.\n",
    "- This iterative process improves the accuracy of the decomposition by adjusting and removing outliers.\n",
    "\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "\n",
    "\n",
    "# STL Decomposition\n",
    "stl = STL(df['Volume'], period=12,seasonal=13)  # 'seasonal' is the window size for seasonal component\n",
    "stl_result = stl.fit()\n",
    "\n",
    "# Plot STL Decomposition\n",
    "fig, axes = plt.subplots(4, 1, figsize=(10, 8))\n",
    "stl_result.observed.plot(ax=axes[0], title='Observed Data')\n",
    "stl_result.trend.plot(ax=axes[1], title='Trend Component')\n",
    "stl_result.seasonal.plot(ax=axes[2], title='Seasonal Component')\n",
    "stl_result.resid.plot(ax=axes[3], title='Residual Component')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stationarity\n",
    "\n",
    "1. **Why do we need stationarity**\n",
    "2. **Types of Stationarity**  \n",
    "   - Weak stationarity  \n",
    "   - Strong stationarity  \n",
    "3. **Testing for Weak Stationarity**\n",
    "4. **Testing for Strict Stationarity**  \n",
    "5. **Making Time Series Stationary**\n",
    "   1. **Differencing**  \n",
    "      - First order  \n",
    "      - Second order  \n",
    "   2. **Transformation**  \n",
    "      - Logarithmic  \n",
    "      - Power  \n",
    "      - Box-Cox  \n",
    "   3. **Detrending**  \n",
    "      - Linear  \n",
    "      - Moving Average  \n",
    "\n",
    "6. **Seasonal Adjustment**\n",
    "\n",
    "7. **Choosing the Right Method**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stationarity:\n",
    "- In time series analysis, stationarity refers to a stochastic process whose statistical properties, including {mean, variance, autocorrelation} remain constant over time.\n",
    "- A stochastic process is a mathematical concept describing a system that evolves over time in a random or unpredictable manner.\n",
    "- Stationary series has no trends or seasonality, making it more predictable for analysis and modeling\n",
    "   ![Stationarity](https://cdn-images-1.medium.com/max/1600/1*tkx0_wwQ2JT7pSlTeg4yzg.png)\n",
    "\n",
    "\n",
    "1. Most statistical smoothing techniques and time series analysis techniques assume that the data is stationary.\n",
    "\n",
    "2.  \n",
    "   ### Strict Stationarity\n",
    "   - The **joint probability distribution** of observations remains unchanged when shifted in time.\n",
    "   - All statistical properties (**mean, variance, higher-order moments, skewness, kurtosis**) are constant over time.\n",
    "   - It is a stricter condition, rarely observed in real-world data.\n",
    "\n",
    "   ### Weak Stationarity (Wide-Sense Stationarity)\n",
    "   - **Constant Mean:** The mean does not vary with time.\n",
    "   - **Constant Variance:** The variance is fixed and does not change over time.\n",
    "   - **Time-Invariant Autocovariance:** Autocovariance depends only on the lag, not the specific time points.\n",
    "\n",
    "   **Note:** Weak stationarity is more practical and commonly used in time series analysis.\n",
    "\n",
    "3. **Weak Stationarity Tests:**\n",
    "   - Augmented Dickey-Fuller (ADF) Test\n",
    "   - KPSS Test\n",
    "   - Phillips-Perron (PP) Test\n",
    "   - ACF & PACF Plots\n",
    "   - Ljung-Box Test\n",
    "   - Variance Ratio Test\n",
    "\n",
    "4. **Strict (Strong) Stationarity Tests:**\n",
    "   - Detrended Fluctuation Analysis (DFA)\n",
    "   - Jarque-Bera Test\n",
    "   - Kolmogorov-Smirnov (KS) Test\n",
    "   - Cusum Test\n",
    "\n",
    "5. **Making Time Series Stationary**\n",
    "\n",
    "   a. **Differencing** makes a time series stationary by subtracting previous values from current ones.\n",
    "      - **1st Order Differencing:** Subtracts value at time `t-1` from value at time `t` to remove linear trends.\n",
    "      - **2nd Order Differencing:** Applies differencing again to remove quadratic trends or further non-stationarity.\n",
    "\n",
    "      **Cons:**\n",
    "      - Can lose long-term trends or relationships.\n",
    "      - May not work well for high volatility or structural changes.\n",
    "\n",
    "   b. **Transformations:**\n",
    "      - **Logarithmic:** Applies the natural logarithm to the data to stabilize variance.\n",
    "      - **Power:** Raises the data to a power (e.g., square root or cube) to stabilize variance.\n",
    "      - **Box-Cox:**\n",
    "         * The Box-Cox transformation is a family of power transformations used to stabilize variance.\n",
    "         * It makes data more normally distributed by applying a parameterized function to positive continuous data.\n",
    "           - \\( Y(\\lambda) = \\frac{Y^{\\lambda} - 1}{\\lambda} \\),  for \\( \\lambda \\neq 0 \\)\n",
    "           - \\( Y(0) = \\ln(Y) \\),  for \\( \\lambda = 0 \\)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
